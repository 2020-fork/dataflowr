{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions by examples\n",
    "\n",
    "### Acknowledgement\n",
    "\n",
    "Code from Sections 1 to 3 taken from [fastai: lesson 0](http://course.fast.ai/lessons/lesson0.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math,sys,os,numpy as np\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download MNIST data on disk and convert it to pytorch compatible formating.\n",
    "\n",
    "```torchvision.datasets``` features support (download, formatting) for a collection of popular datasets. The list of available datasets in ```torchvision``` can be found [here](http://pytorch.org/docs/master/torchvision/datasets.html).\n",
    "\n",
    "Note that the download is performed only once. The function will always check first if the data is already on disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be modified!\n",
    "root_dir = '/home/lelarge/courses/data/MNIST/'\n",
    "torchvision.datasets.MNIST(root=root_dir,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST datasets consists of small images of hand-written digits. The images are grayscale and have size 28 x 28. There are 60,000 training images and 10,000 testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(root=root_dir, train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize a data loader for the MNIST data already downloaded on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_dataset = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current notebook, since we are doing no training, we can format data as _numpy ndarrays_ which are easier to plot in matplotlib. The same operations can be easily performed on _pytorch Tensors_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = train_set.train_data.numpy().astype(np.float32)/255\n",
    "b = train_set.train_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape,b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data as compressed ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(root_dir, 'train'), images=a, labels=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we define a few functions for formatting and plotting our image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot multiple images\n",
    "def plots(ims, interp=False, titles=None):\n",
    "    ims=np.array(ims)\n",
    "    mn,mx=ims.min(),ims.max()\n",
    "    f = plt.figure(figsize=(12,24))\n",
    "    for i in range(len(ims)):\n",
    "        sp=f.add_subplot(1, len(ims), i+1)\n",
    "        if not titles is None: sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none', vmin=mn,vmax=mx)\n",
    "\n",
    "# plot a single image\n",
    "def plot(im, interp=False):\n",
    "    f = plt.figure(figsize=(3,6), frameon=True)\n",
    "    plt.imshow(im, interpolation=None if interp else 'none')\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join(root_dir, 'train.npz'))\n",
    "images=data['images']\n",
    "labels=data['labels']\n",
    "n=len(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(images[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(images[5000:5005], titles=labels[5000:5005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filters and convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple 3x3 filter, ie a 3x3 matrix (see [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) for more examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top=[[-1,-1,-1],\n",
    "     [ 1, 1, 1],\n",
    "     [ 0, 0, 0]]\n",
    "\n",
    "plot(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross = np.zeros((28,28))\n",
    "cross += np.eye(28)\n",
    "for i in range(4):\n",
    "    cross[12+i,:] = np.ones(28)\n",
    "    cross[:,12+i] = np.ones(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some fields, convolution or filtering can be better understood as _correlations_. \n",
    "In practice we slide the filter matrix over the image (a bigger matrix) always selecting patches from the image with the same size as the filter. We compute the dot product between the filter and the image patch and store the scalar response which reflects the degree of similarity/correlation between the filter and image patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import convolve, correlate\n",
    "\n",
    "corr_cross = correlate(cross,top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(corr_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the role of padding\n",
    "corr_cross = correlate(cross,top, mode='constant')\n",
    "plot(corr_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrtop = correlate(images[5000], top)\n",
    "plot(corrtop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By rotating the filter with 90 degrees and calling the ```convolve``` function we get the same response as with the previously called ```correlate``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.rot90(top, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convtop = convolve(images[5000], np.rot90(top,2))\n",
    "plot(convtop)\n",
    "np.allclose(convtop, corrtop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a few more variants of our simple 3x3 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "straights=[np.rot90(top,i) for i in range(4)]\n",
    "plots(straights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed similarly to generate a set of filters with a different behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br=[[ 0, 0, 1],\n",
    "    [ 0, 1,-1.5],\n",
    "    [ 1,-1.5, 0]]\n",
    "\n",
    "diags = [np.rot90(br,i) for i in range(4)]\n",
    "plots(diags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compose filters to obtain more complex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = straights + diags\n",
    "corrs_cross = [correlate(cross, rot) for rot in rots]\n",
    "plots(corrs_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = straights + diags\n",
    "corrs = [correlate(images[5000], rot) for rot in rots]\n",
    "plots(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we illustrate the effect of downsampling.\n",
    "We select the most basic downsampling technique: __max pooling__. We keep only the maximum value for sliding windows of size ```7x7```.\n",
    "__Max pooling__ is a handy technique with a few useful perks:\n",
    "- since it selects the maximum values it ensures invariance to translations\n",
    "- reducing the size is helpful since data becomes more compact and easier to compare\n",
    "- we will see later in this course that since max pooling reduces the size of our images, the operations performed later on in the network have bigger receptive field / concern a bigger patch in the input image and allow the discovery of higher level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might need to install scikit-image by typing the following line:\n",
    "#conda install -c conda-forge scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "def pool(im): return block_reduce(im, (7,7), np.max)\n",
    "\n",
    "plots([pool(im) for im in corrs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will construct a basic classifier similar to k-nearest neighbors.\n",
    "Our classifier will tell us whether a given image depicts a _one_ or an _eight_.\n",
    "\n",
    "To this end we select a set of training images depicting _eights_ and _ones_, we convolve them with our set of filters, pool them and average them for each class and filter. We will thus obtain a set of _representative_ signatures for _eights_ and for _ones_. \n",
    "Given a new test image we compute its features by convolution and pooling with the same filters and then compare them with the _representative_ features. The class with the most _similar_ features is chosen as prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch all images from the _eight_ class and from the _one_ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eights=[images[i] for i in range(n) if labels[i]==8]\n",
    "ones=[images[i] for i in range(n) if labels[i]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eights), len(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(eights[:5])\n",
    "plots(ones[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the first 1000 digits for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raws8 =  np.mean(eights[1000:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(raws8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raws1 =  np.mean(ones[1000:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(raws1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum of squared errors\n",
    "def sse(a,b): return ((a-b)**2).sum()\n",
    "\n",
    "def is8_raw_n2(im): return 1 if sse(im,raws1) > sse(im,raws8) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([is8_raw_n2(im) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([(1-is8_raw_n2(im)) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Precisionrecall.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_8 = 912/(912+27)\n",
    "Recall_8 = 912/1000\n",
    "Precision_1 = 973/(973+88)\n",
    "Recall_1 = 973/1000\n",
    "\n",
    "print('precision 8:', Precision_8, 'recall 8:', Recall_8)\n",
    "print('precision 1:', Precision_1, 'recall 1:', Recall_1)\n",
    "print('accuracy :', (Recall_1+Recall_8)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a classifier with convolutions.\n",
    "\n",
    "We keep 1000 images of _eight_ for the test set and use the remaining ones for the training: we convolve them with our bank of filters, perform max pooling on the responses and store them in ```pool8```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool8 = [np.array([pool(correlate(im, rot)) for im in eights[1000:]]) for rot in rots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pool8), pool8[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the result of the first filter+pooling on the first 5 _eights_ in our set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(pool8[0][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 3 first _eightts_ in our set, we plot the result of the 8 filters+pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots([pool8[i][0] for i in range(8)])\n",
    "plots([pool8[i][1] for i in range(8)])\n",
    "plots([pool8[i][2] for i in range(8)])\n",
    "plots([pool8[i][3] for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data in order to smoothen activations and bring them to similar ranges of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(arr): return (arr-arr.mean())/arr.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute the average _eight_ by averaging all responses for each filter from _rots_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filts8 = np.array([ims.mean(axis=0) for ims in pool8])\n",
    "filts8 = normalize(filts8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should obtain a set of canonical _eights_ responses for each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(filts8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed similarly with training samples from the _one_ class and plot the canonical _ones_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool1 = [np.array([pool(correlate(im, rot)) for im in ones[1000:]]) for rot in rots]\n",
    "filts1 = np.array([ims.mean(axis=0) for ims in pool1])\n",
    "filts1 = normalize(filts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(filts1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any differences between ```filts8``` and ```filts1```? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that correlates a given image with all filters from ```rots``` and max pools the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool_corr(im): return np.array([pool(correlate(im, rot)) for rot in rots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(pool_corr(eights[1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check \n",
    "plots([pool8[i][0] for i in range(8)])\n",
    "np.allclose(pool_corr(eights[1000]),[pool8[i][0] for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function used for a voting based classifier that will indicate which one of the \n",
    "# two classes is most likely given the sse distances\n",
    "# n2 comes from norm2\n",
    "# is8_n2 returns 1 if it thinks it's an eight and 0 otherwise\n",
    "def is8_n2(im): return 1 if sse(pool_corr(im),filts1) > sse(pool_corr(im),filts8) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a check to see if our function actually works. We correlate the an image of _eight_ with ```filts8``` and ```filts1```. It should give smaller error for the _eights_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse(pool_corr(eights[0]), filts8), sse(pool_corr(eights[0]), filts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(eights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test our classifier on the 1000 images of _eights_ and 1000 images of _ones_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([is8_n2(im) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It said in 969 cases it is an _eight_ and 37 case it is a _one_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test the opposite, ie it's not an _eight_ , it's not a _one_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([(1-is8_n2(im)) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_8 = 969/(969+37)\n",
    "Recall_8 = 969/1000\n",
    "Precision_1 = 963/(963+31)\n",
    "Recall_1 = 963/1000\n",
    "\n",
    "print('precision 8:', Precision_8, 'recall 8:', Recall_8)\n",
    "print('precision 1:', Precision_1, 'recall 1:', Recall_1)\n",
    "print('accuracy :', (Recall_1+Recall_8)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved the accuracy while reducing the embedding size from a $28\\times 28 = 784$ vector to a $4\\times 4\\times 8 = 128$ vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the our simple classifier with a new distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum of absolute differences\n",
    "def n1(a,b): return (np.fabs(a-b)).sum()\n",
    "\n",
    "# is8_n1 returns 1 if it thinks it's an eight and 0 otherwise\n",
    "def is8_n1(im): return 1 if n1(pool_corr(im),filts1) > n1(pool_corr(im),filts8) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([is8_n1(im) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array([(1-is8_n1(im)) for im in ims]).sum() for ims in [eights[:1000],ones[:1000]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully built a classifier for _eights_ and _ones_ using features extract with a bank of pre-defined features and a set of training samples. We will improved it during the next lectures.\n",
    "\n",
    "#### Questions\n",
    "- What are the advantages of this method?\n",
    "- What are the weak points of this method?\n",
    "- How can we improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A few useful ressources about convolutions:\n",
    "1. [Convolution animations](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)\n",
    "2. [Interactive image kernels](http://setosa.io/ev/image-kernels/)\n",
    "3. [CS231n: Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Practicals: improving classification with Convolutional Neural Net\n",
    "\n",
    "You will now build a neural net that will learn the weights of the filters.\n",
    "\n",
    "The first layer of your network will be a convolutional layer with $8$ filters of size $3\\times 3$ as we did above. Then you apply a maxpooling layer with kernel size $7\\times 7$. This will produce a (once flatten) a vector of size $128 = 4\\times 4\\times 8$. From this vector, you need to predict if the corresponding input is a $1$ or a $8$. So you are back to a classification problem or logistic regression, i.e. from there you can apply the solution of previous homework!\n",
    "\n",
    "You need to fill the code written below to construct your CNN. You will need to look for documentation about [torch.nn](https://pytorch.org/docs/stable/nn.html) in the Pytorch doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        # fill the missing entries below\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=?)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # implement your network here, use F.max_pool2d, F.log_softmax and do not forget to flatten your vector\n",
    "        x = self.conv1(x)\n",
    "        #\n",
    "        # Your code here\n",
    "        #\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_class = classifier()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    conv_class = conv_class.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should work fine on a batch of 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_3images = train_set.train_data[0:2].type(torch.FloatTensor).resize_(3, 1, 28, 28)\n",
    "conv_class(batch_3images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code implement a data loader for the train set and the test set. No modification is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "l8 = np.array(0)\n",
    "eights_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), torch.from_numpy(l8.astype(np.int64))] for e in eights]\n",
    "l1 = np.array(1)\n",
    "ones_dataset = [[torch.from_numpy(e.astype(np.float32)).unsqueeze(0), torch.from_numpy(l1.astype(np.int64))] for e in ones]\n",
    "train_dataset = eights_dataset[1000:] + ones_dataset[1000:]\n",
    "test_dataset = eights_dataset[:1000] + ones_dataset[:1000]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "    batch_size=bs, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "    batch_size=bs, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need now to code the training loop. Store the loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    acc_train = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            bs = labels.size(0)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs.cuda()\n",
    "            #\n",
    "            #\n",
    "            # Your code here\n",
    "            #\n",
    "            #\n",
    "            size += bs\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.item() / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_class = classifier()\n",
    "# choose the appropriate loss\n",
    "loss_fn = \n",
    "learning_rate = 1e-3\n",
    "# your SGD optimizer\n",
    "optimizer_cl = \n",
    "# and train for 10 epochs\n",
    "l_t, a_t = train(conv_class,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn for 10 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_t1, a_t1 = train(conv_class,train_loader,loss_fn,optimizer_cl,n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network seems to learn but we now need to check its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data    \n",
    "        bs = labels.size(0)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs.cuda()\n",
    "                \n",
    "        #\n",
    "        # Your code here\n",
    "        #\n",
    "        size += bs\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(conv_class,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the optimizer to Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many parameters did your network learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in conv_class.children():\n",
    "    print('weights :', m.weight.data)\n",
    "    print('bias :', m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in conv_class.children():\n",
    "    T_w = m.weight.data.numpy()\n",
    "    T_b = m.bias.data.numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plots([T_w[i][0] for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "0468b419a96749ec9b4cb1abdd4626f7": {
     "views": []
    },
    "2d3eeb645fa442fcb882ae96a9387e3d": {
     "views": []
    },
    "32cface5fd2d422480c840a0dbb1852d": {
     "views": []
    },
    "3d7fbc924d804aa1b0b751d1c4d9d42a": {
     "views": []
    },
    "60b62dbd86494ef0bc136aef4657b05f": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "879e65eadeba4a66bd0759b2918fa9f0": {
     "views": []
    },
    "8cd5af0fc89d43d4ae9b786c1f886bee": {
     "views": []
    },
    "c3a89a0403354dd19a296fd30376a143": {
     "views": []
    },
    "c997f4ebd8874aaea6ea7b699afc9a27": {
     "views": []
    },
    "ff487921e8134858a58437f0558fd42f": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
